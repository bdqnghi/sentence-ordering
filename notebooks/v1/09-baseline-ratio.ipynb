{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, path, skim=None):\n",
    "        self.path = path\n",
    "        self.skim = skim\n",
    "        \n",
    "    def lines(self):\n",
    "        with open(self.path) as fh:\n",
    "            for line in fh:\n",
    "                yield line.strip()\n",
    "    \n",
    "    def abstract_lines(self):\n",
    "        lines = []\n",
    "        for line in self.lines():\n",
    "            if line:\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                yield lines\n",
    "                lines = []\n",
    "\n",
    "    def abstracts(self):\n",
    "        ab_lines = self.abstract_lines()\n",
    "        if self.skim:\n",
    "            ab_lines = islice(ab_lines, self.skim)\n",
    "        for lines in ab_lines:\n",
    "            yield Abstract.from_lines(lines)\n",
    "            \n",
    "    def xy(self, vocab):\n",
    "        for abstract in self.abstracts():\n",
    "            yield from abstract.xy(vocab)\n",
    "            \n",
    "    def token_counts(self):\n",
    "        counts = defaultdict(lambda: 0)\n",
    "        for ab in self.abstracts():\n",
    "            for tokens in ab.sentence_tokens():\n",
    "                for token in tokens:\n",
    "                    counts[token] += 1\n",
    "        return Counter(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Abstract:\n",
    "    \n",
    "    identifier = attr.ib()\n",
    "    tags = attr.ib()\n",
    "    sentences = attr.ib()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_lines(cls, lines):\n",
    "        return cls(lines[0], lines[1].split(), lines[2:])\n",
    "    \n",
    "    def sentence_tokens(self):\n",
    "        for sent in self.sentences:\n",
    "            yield re.findall('[a-z]+', sent.lower())\n",
    "    \n",
    "    def xy(self, vocab):\n",
    "        sent_tokens = list(self.sentence_tokens())\n",
    "        for i, tokens in enumerate(sent_tokens):\n",
    "            x = Counter([t for t in tokens if t in vocab])\n",
    "            y = i / (len(sent_tokens)-1)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Corpus('../data/abstracts/train.txt', 1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train.token_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([k for k, _ in counts.most_common(2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*train.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4758878x2000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 83076373 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Corpus('../data/abstracts/test.txt', 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = zip(*test.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27807718715938701"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_y, fit.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidx = fit.coef_.argsort()\n",
    "eidx = np.flip(fit.coef_.argsort(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2196469005 let\n",
      "-0.163229038677 often\n",
      "-0.147029501012 report\n",
      "-0.141095645196 usually\n",
      "-0.138353329268 investigate\n",
      "-0.131485351099 aim\n",
      "-0.131182990641 paper\n",
      "-0.128837459361 consider\n",
      "-0.128657935972 widely\n",
      "-0.128047283648 investigated\n",
      "-0.12582735115 article\n",
      "-0.125357963763 phys\n",
      "-0.119351134853 recently\n",
      "-0.110511990421 study\n",
      "-0.110369806736 studied\n",
      "-0.107565703088 theoretically\n",
      "-0.104208645257 goal\n",
      "-0.0977081210248 telescope\n",
      "-0.0949798582031 presents\n",
      "-0.0856493461534 superconductor\n",
      "-0.0855591158579 qcd\n",
      "-0.0846083395821 called\n",
      "-0.0830839664757 photometry\n",
      "-0.0827291581215 electroweak\n",
      "-0.0813302230393 superconductors\n",
      "-0.0801618758471 examine\n",
      "-0.0798485175169 purpose\n",
      "-0.0788851028823 relativity\n",
      "-0.078548025611 supersymmetric\n",
      "-0.07834622373 known\n",
      "-0.0776480427997 review\n",
      "-0.0751008840151 recent\n",
      "-0.0734146320682 difficult\n",
      "-0.0716923000833 typically\n",
      "-0.0713598054977 survey\n",
      "-0.0712463391858 crystals\n",
      "-0.0695670070584 attention\n",
      "-0.0679890418682 past\n",
      "-0.0656842861938 task\n",
      "-0.0656602326798 human\n",
      "-0.0655104100351 communication\n",
      "-0.0651439776277 introduce\n",
      "-0.0647214527088 many\n",
      "-0.0633283886208 years\n",
      "-0.0632715160432 introduced\n",
      "-0.0631539811174 collider\n",
      "-0.0630750733769 present\n",
      "-0.0629599707279 subject\n",
      "-0.0627239199598 motivated\n",
      "-0.0626121735598 newton\n"
     ]
    }
   ],
   "source": [
    "for i in bidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.367760739846 finally\n",
      "0.297268892857 conclude\n",
      "0.21895105414 furthermore\n",
      "0.204388266138 moreover\n",
      "0.201514367237 also\n",
      "0.187678693509 illustrate\n",
      "0.166043314562 implications\n",
      "0.15565249018 examples\n",
      "0.153093124303 suggests\n",
      "0.15308407343 further\n",
      "0.15060439333 discussed\n",
      "0.150043503949 addition\n",
      "0.149034062511 findings\n",
      "0.142817336891 application\n",
      "0.135847771445 briefly\n",
      "0.134114866671 suggest\n",
      "0.124569584459 consequence\n",
      "0.12454008341 indicates\n",
      "0.119905669278 example\n",
      "0.118330985559 our\n",
      "0.117457865096 future\n",
      "0.112244733099 suggesting\n",
      "0.111784482636 agreement\n",
      "0.109328628418 thus\n",
      "0.107292076219 discussion\n",
      "0.105541117623 particular\n",
      "0.104465315487 therefore\n",
      "0.100865534773 demonstrate\n",
      "0.100354013203 argue\n",
      "0.0988056814968 proof\n",
      "0.0972607217136 then\n",
      "0.0937141990988 demonstrated\n",
      "0.0923514784713 results\n",
      "0.0902866124149 find\n",
      "0.0898367338515 result\n",
      "0.0897251566289 could\n",
      "0.0895961759623 explained\n",
      "0.0891477674541 tested\n",
      "0.0875348506369 indicating\n",
      "0.0874712811641 these\n",
      "0.0854088390328 this\n",
      "0.0839150482928 confirm\n",
      "0.0838889724238 will\n",
      "0.0829391470395 consequences\n",
      "0.0828932916391 comparison\n",
      "0.0824620079908 indicate\n",
      "0.0814942429498 likely\n",
      "0.0785149160432 discuss\n",
      "0.0783699145074 might\n",
      "0.0776743894768 confirmed\n"
     ]
    }
   ],
   "source": [
    "for i in eidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
