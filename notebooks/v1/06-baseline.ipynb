{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. just bow\n",
    "1. pos\n",
    "1. sent len, word len, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "from tqdm import tqdm_notebook as bar\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "    def lines(self):\n",
    "        with open(self.path) as fh:\n",
    "            for line in fh:\n",
    "                yield line.strip()\n",
    "    \n",
    "    def abstract_lines(self):\n",
    "        lines = []\n",
    "        for line in self.lines():\n",
    "            if line:\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                yield lines\n",
    "                lines = []\n",
    "                \n",
    "    def abstracts(self):\n",
    "        for lines in self.abstract_lines():\n",
    "            yield Abstract.from_lines(lines)\n",
    "            \n",
    "    def xy(self):\n",
    "        for abstract in self.abstracts():\n",
    "            yield from abstract.xy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Abstract:\n",
    "    \n",
    "    identifier = attr.ib()\n",
    "    tags = attr.ib()\n",
    "    sentences = attr.ib()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_lines(cls, lines):\n",
    "        return cls(lines[0], lines[1].split(), lines[2:])\n",
    "    \n",
    "    def xy(self):\n",
    "        for y, sent in enumerate(self.sentences):\n",
    "            tokens = re.findall('[a-z]+', sent.lower())\n",
    "            x = dict(Counter(tokens))\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Corpus('../data/abstracts/train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*islice(train.xy(), 300000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<300000x68321 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6363071 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Corpus('../data/abstracts/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = zip(*islice(test.xy(), 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.019257919496291853"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_y, fit.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidx = fit.coef_.argsort()\n",
    "eidx = np.flip(fit.coef_.argsort(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.6203649077 osteoclast\n",
      "-18.5355845999 trabecular\n",
      "-17.9417328524 jswt\n",
      "-17.8524440701 driemel\n",
      "-15.870660574 madc\n",
      "-15.7539119351 dsls\n",
      "-14.7806331809 medal\n",
      "-14.6025215955 beringei\n",
      "-14.6025215955 graueri\n",
      "-14.5399094982 dehydration\n",
      "-13.6006905655 adt\n",
      "-13.5092456511 noy\n",
      "-13.3484313982 awdrat\n",
      "-13.1112707521 lstar\n",
      "-12.5992748528 visone\n",
      "-12.5715964877 mad\n",
      "-12.4504417208 fltz\n",
      "-12.2332370437 arkhipov\n",
      "-12.159701377 moghanjoughi\n",
      "-12.0216646274 titius\n",
      "-11.9909223093 perles\n",
      "-11.9298114633 anowski\n",
      "-11.8530596779 derepression\n",
      "-11.5418878314 saraykoy\n",
      "-11.4951830493 nonpositve\n",
      "-11.4927466852 aec\n",
      "-11.4475839104 lanzhou\n",
      "-11.0821181309 scala\n",
      "-10.9876494666 wvb\n",
      "-10.8207547164 taskforce\n",
      "-10.6124515354 psoriatic\n",
      "-10.5283636017 winternitz\n",
      "-10.3999152757 midday\n",
      "-10.3112545438 sandhas\n",
      "-10.2914132211 cavi\n",
      "-9.9905480091 solstice\n",
      "-9.98230403353 silicalite\n",
      "-9.92906623756 schlag\n",
      "-9.84131704077 dcls\n",
      "-9.81328330168 lascu\n",
      "-9.75710266655 scab\n",
      "-9.75710266655 blotch\n",
      "-9.70761722998 phonetically\n",
      "-9.545980135 lox\n",
      "-9.54495913134 liceum\n",
      "-9.5335499264 kreckel\n",
      "-9.51031900965 aszl\n",
      "-9.49746089459 kudryavtseva\n",
      "-9.44108568875 caida\n",
      "-9.42124629436 grns\n"
     ]
    }
   ],
   "source": [
    "for i in bidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.9188804699 superfilters\n",
      "18.8427232628 chalonge\n",
      "17.9248559228 dcg\n",
      "16.6531617316 quarrks\n",
      "15.5868113333 kno\n",
      "15.5025898373 heterochromatin\n",
      "15.2781215252 kulkarni\n",
      "14.6977091709 ldust\n",
      "14.4990358164 fukue\n",
      "14.2208955092 neutrinno\n",
      "14.1238048741 superpolynomially\n",
      "13.7912389505 staining\n",
      "13.7677104394 derma\n",
      "13.6519161378 aodvers\n",
      "13.6399354759 opalescent\n",
      "13.519131663 resemblances\n",
      "13.4906333744 reification\n",
      "13.147405749 derenzo\n",
      "12.8290086543 evora\n",
      "12.4396013098 grasmannian\n",
      "12.1291636125 seh\n",
      "12.0091803957 zhai\n",
      "12.0078366158 fvm\n",
      "11.9696597097 nonreversibility\n",
      "11.8748029108 artir\n",
      "11.7604292988 mtminer\n",
      "11.7343740297 interm\n",
      "11.7078532589 methylstyrene\n",
      "11.6913473731 bosonn\n",
      "11.6913410287 albumin\n",
      "11.6055853223 femur\n",
      "11.5623085894 welland\n",
      "11.5285165703 evening\n",
      "11.5079287314 subsuming\n",
      "11.3851701523 lepp\n",
      "11.3718280425 microct\n",
      "11.2504217227 maria\n",
      "11.1626172626 warned\n",
      "11.1360955612 streaked\n",
      "11.1335989017 joyal\n",
      "10.9682770438 infelicitous\n",
      "10.9603912796 curbing\n",
      "10.9386723446 graviational\n",
      "10.8795327156 antidiamond\n",
      "10.8174311966 subsumptive\n",
      "10.8003272731 aronszajn\n",
      "10.6784313509 stiki\n",
      "10.663920413 pathologists\n",
      "10.6352753649 halls\n",
      "10.6169610166 vachkovskaia\n"
     ]
    }
   ],
   "source": [
    "for i in eidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
