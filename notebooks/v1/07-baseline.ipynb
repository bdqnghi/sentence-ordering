{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, path, skim=None):\n",
    "        self.path = path\n",
    "        self.skim = skim\n",
    "        \n",
    "    def lines(self):\n",
    "        with open(self.path) as fh:\n",
    "            for line in fh:\n",
    "                yield line.strip()\n",
    "    \n",
    "    def abstract_lines(self):\n",
    "        lines = []\n",
    "        for line in self.lines():\n",
    "            if line:\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                yield lines\n",
    "                lines = []\n",
    "\n",
    "    def abstracts(self):\n",
    "        ab_lines = self.abstract_lines()\n",
    "        if self.skim:\n",
    "            ab_lines = islice(ab_lines, self.skim)\n",
    "        for lines in ab_lines:\n",
    "            yield Abstract.from_lines(lines)\n",
    "            \n",
    "    def xy(self, vocab):\n",
    "        for abstract in self.abstracts():\n",
    "            yield from abstract.xy(vocab)\n",
    "            \n",
    "    def token_counts(self):\n",
    "        counts = Counter()\n",
    "        for ab in self.abstracts():\n",
    "            for tokens in ab.sentence_tokens():\n",
    "                counts += Counter(tokens)\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Abstract:\n",
    "    \n",
    "    identifier = attr.ib()\n",
    "    tags = attr.ib()\n",
    "    sentences = attr.ib()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_lines(cls, lines):\n",
    "        return cls(lines[0], lines[1].split(), lines[2:])\n",
    "    \n",
    "    def sentence_tokens(self):\n",
    "        for sent in self.sentences:\n",
    "            yield re.findall('[a-z]+', sent.lower())\n",
    "    \n",
    "    def xy(self, vocab):\n",
    "        for y, tokens in enumerate(self.sentence_tokens()):\n",
    "            x = Counter([t for t in tokens if t in vocab])\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Corpus('../data/abstracts/train.txt', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train.token_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([k for k, _ in counts.most_common(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*train.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<53739x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 819171 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Corpus('../data/abstracts/test.txt', 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = zip(*test.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16580631441074212"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_y, fit.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidx = fit.coef_.argsort()\n",
    "eidx = np.flip(fit.coef_.argsort(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.03581946915 report\n",
      "-1.02835405239 let\n",
      "-0.914497597299 investigate\n",
      "-0.846844203299 al\n",
      "-0.830184587498 article\n",
      "-0.78163341155 recent\n",
      "-0.757251426661 examine\n",
      "-0.741650049954 investigated\n",
      "-0.74088390302 carlo\n",
      "-0.723502363229 consider\n",
      "-0.720023497564 study\n",
      "-0.688595456941 survey\n",
      "-0.68076483802 recently\n",
      "-0.64960052304 telescope\n",
      "-0.647065037145 manifolds\n",
      "-0.644762820453 paper\n",
      "-0.619716594307 studied\n",
      "-0.604969614124 laser\n",
      "-0.58657661926 collisions\n",
      "-0.576231418038 supersymmetric\n",
      "-0.572544657412 superconducting\n",
      "-0.571828226862 qcd\n",
      "-0.558770243668 deep\n",
      "-0.556927687653 neutrino\n",
      "-0.548461252921 present\n",
      "-0.539333841508 atomic\n",
      "-0.536703146039 heat\n",
      "-0.515898928237 introduce\n",
      "-0.507475079512 introduced\n",
      "-0.50589234049 quark\n",
      "-0.498517965028 detector\n",
      "-0.490626183995 canonical\n",
      "-0.468951680846 basic\n",
      "-0.466597914503 review\n",
      "-0.463411717608 sequence\n",
      "-0.458595662807 taking\n",
      "-0.449025346291 active\n",
      "-0.440712797268 infrared\n",
      "-0.435981039214 known\n",
      "-0.430630619422 decays\n",
      "-0.42982338149 lhc\n",
      "-0.425424811899 dispersion\n",
      "-0.414817886321 medium\n",
      "-0.413680259408 entanglement\n",
      "-0.409914055093 periodic\n",
      "-0.394376820066 production\n",
      "-0.394178314047 fundamental\n",
      "-0.388489877853 been\n",
      "-0.384036051911 spectroscopy\n",
      "-0.378380222108 physics\n"
     ]
    }
   ],
   "source": [
    "for i in bidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.65772562297 finally\n",
      "1.36091165965 furthermore\n",
      "1.10032236784 suggests\n",
      "1.05207885558 likely\n",
      "1.03983679017 also\n",
      "1.01671976192 could\n",
      "0.971557985147 moreover\n",
      "0.927273223944 suggest\n",
      "0.914853856362 further\n",
      "0.888437581213 therefore\n",
      "0.862116291344 would\n",
      "0.83410057832 our\n",
      "0.805941867338 thus\n",
      "0.763715659562 addition\n",
      "0.760194778601 et\n",
      "0.745486412053 future\n",
      "0.742147928401 agreement\n",
      "0.702527743588 example\n",
      "0.683383316532 better\n",
      "0.660295184184 consistent\n",
      "0.625101118592 examples\n",
      "0.614213598269 smaller\n",
      "0.581573888967 explain\n",
      "0.569837331063 less\n",
      "0.540012897876 similar\n",
      "0.530395535949 dust\n",
      "0.522486797921 scenario\n",
      "0.51678362572 fit\n",
      "0.516417457861 monte\n",
      "0.513047643445 uv\n",
      "0.50172526165 required\n",
      "0.498455515946 latter\n",
      "0.491942143101 discussed\n",
      "0.477243388645 application\n",
      "0.470308389909 abundance\n",
      "0.457692322662 shock\n",
      "0.452193220649 additional\n",
      "0.444230576243 should\n",
      "0.43806749615 disk\n",
      "0.437307457201 significant\n",
      "0.431270219385 then\n",
      "0.429391853738 section\n",
      "0.427675138854 larger\n",
      "0.425860355035 cases\n",
      "0.425196246248 early\n",
      "0.421855135568 however\n",
      "0.416276785775 simulation\n",
      "0.416019034441 these\n",
      "0.414884604193 do\n",
      "0.408045444357 changes\n"
     ]
    }
   ],
   "source": [
    "for i in eidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
