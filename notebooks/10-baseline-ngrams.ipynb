{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bigrams / trigrams\n",
    "- pos tags\n",
    "- word count\n",
    "- avg word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "from boltons.iterutils import windowed\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, path, skim=None):\n",
    "        self.path = path\n",
    "        self.skim = skim\n",
    "        \n",
    "    def lines(self):\n",
    "        with open(self.path) as fh:\n",
    "            for line in fh:\n",
    "                yield line.strip()\n",
    "    \n",
    "    def abstract_lines(self):\n",
    "        lines = []\n",
    "        for line in self.lines():\n",
    "            if line:\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                yield lines\n",
    "                lines = []\n",
    "\n",
    "    def abstracts(self):\n",
    "        ab_lines = self.abstract_lines()\n",
    "        if self.skim:\n",
    "            ab_lines = islice(ab_lines, self.skim)\n",
    "        for lines in ab_lines:\n",
    "            yield Abstract.from_lines(lines)\n",
    "            \n",
    "    def xy(self, vocab):\n",
    "        for abstract in self.abstracts():\n",
    "            yield from abstract.xy(vocab)\n",
    "            \n",
    "    def ngram_counts(self, n):\n",
    "        counts = defaultdict(lambda: 0)\n",
    "        for ab in self.abstracts():\n",
    "            for sent in ab.sentences:\n",
    "                for ngram in sent.ngrams(n):\n",
    "                    counts[ngram] += 1\n",
    "        return Counter(counts)\n",
    "            \n",
    "    def most_common_ngrams(self, n, depth):\n",
    "        counts = self.ngram_counts(n)\n",
    "        return set([k for k, _ in counts.most_common(depth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Abstract:\n",
    "    \n",
    "    identifier = attr.ib()\n",
    "    tags = attr.ib()\n",
    "    sentences = attr.ib()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_lines(cls, lines):\n",
    "        sentences = list(map(Sentence, lines[2:]))\n",
    "        return cls(lines[0], lines[1].split(), sentences)\n",
    "    \n",
    "    def sentence_tokens(self):\n",
    "        for sent in self.sentences:\n",
    "            yield re.findall('[a-z]+', sent.lower())\n",
    "    \n",
    "    def xy(self, vocab):\n",
    "        for i, sent in enumerate(self.sentences):\n",
    "            x = sent.features(vocab)\n",
    "            y = i / (len(self.sentences)-1)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence(str):\n",
    "    \n",
    "    def ngrams(self, n=1):\n",
    "        for ng in windowed(re.findall('[a-z]+', self.lower()), n):\n",
    "            yield '_'.join(ng)\n",
    "            \n",
    "    def ngram_counts(self, vocab, maxn=3):\n",
    "        for n in range(1, maxn+1):\n",
    "            counts = Counter(self.ngrams(n))\n",
    "            for k, v in counts.items():\n",
    "                if k in vocab:\n",
    "                    yield f'_{k}', v\n",
    "                    \n",
    "    def word_count(self):\n",
    "        return len(list(self.ngrams(1)))\n",
    "                \n",
    "    def _features(self, vocab):\n",
    "        yield from self.ngram_counts(vocab)\n",
    "        yield 'word_count', self.word_count()\n",
    "        \n",
    "    def features(self, vocab):\n",
    "        return dict(self._features(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Corpus('../data/abstracts/train.txt', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = (\n",
    "    train.most_common_ngrams(1, 2000) |\n",
    "    train.most_common_ngrams(2, 2000) |\n",
    "    train.most_common_ngrams(3, 2000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*train.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<537608x6001 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 14417053 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Corpus('../data/abstracts/test.txt', 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = zip(*test.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31405170105717162"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_y, fit.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidx = fit.coef_.argsort()\n",
    "eidx = np.flip(fit.coef_.argsort(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.362227873011 _particular_we\n",
      "-0.346649231987 _other_hand\n",
      "-0.290147875223 _of_the_art\n",
      "-0.223934412029 _in_addition_to\n",
      "-0.222645721932 _the_help_of\n",
      "-0.221488724522 _this_note\n",
      "-0.219692924447 _the_context_of\n",
      "-0.211999084165 _de_sitter\n",
      "-0.207407879161 _we_study\n",
      "-0.196496695992 _with_respect_to\n",
      "-0.189540609743 _functional_theory\n",
      "-0.187536224922 _this_paper\n",
      "-0.183791156946 _let\n",
      "-0.179435527391 _is_considered\n",
      "-0.173901949213 _an_application_we\n",
      "-0.162243217408 _the_importance_of\n",
      "-0.158666751094 _is_presented\n",
      "-0.157887836199 _in_terms_of\n",
      "-0.157371060502 _is_studied\n",
      "-0.156861045663 _this_article\n",
      "-0.155969339387 _we_investigate\n",
      "-0.15461437997 _we_report\n",
      "-0.153550938327 _is_one_of\n",
      "-0.144508507766 _next_to\n",
      "-0.141802444779 _the_first_part\n",
      "-0.141762520169 _in_a_recent\n",
      "-0.138054289806 _and_therefore\n",
      "-0.137812758911 _we_present_results\n",
      "-0.137413890615 _often\n",
      "-0.137235351663 _usually\n",
      "-0.136221638771 _is_devoted_to\n",
      "-0.135980506832 _has_been_studied\n",
      "-0.135019763023 _our_results_show\n",
      "-0.130243915465 _the_first_time\n",
      "-0.129771410142 _we_present\n",
      "-0.129624201379 _but_also\n",
      "-0.129473500313 _compare_our_results\n",
      "-0.127262439405 _known_as\n",
      "-0.12594293744 _are_known_to\n",
      "-0.124442367634 _the_proof_of\n",
      "-0.122801320931 _gamma_ray_burst\n",
      "-0.12230093469 _we_generalize_the\n",
      "-0.121012240296 _we_consider\n",
      "-0.120561091711 _the_notion_of\n",
      "-0.119935663198 _known_that\n",
      "-0.119466719705 _et_al\n",
      "-0.119412412846 _we_discuss_a\n",
      "-0.119281433778 _an_integrated_luminosity\n",
      "-0.119201748489 _we_also_find\n",
      "-0.118306071808 _sloan_digital_sky\n"
     ]
    }
   ],
   "source": [
    "for i in bidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.478077373137 _the_other_hand\n",
      "0.440654498302 _in_particular_we\n",
      "0.391670639845 _the_art\n",
      "0.330302683186 _finally\n",
      "0.252279513329 _as_a_corollary\n",
      "0.250197946699 _application_we\n",
      "0.225824318739 _here_we_report\n",
      "0.208730416395 _conclude\n",
      "0.201093055597 _furthermore\n",
      "0.199312299367 _in_addition\n",
      "0.196532436115 _comment_on_the\n",
      "0.195325913805 _with_respect\n",
      "0.193732091719 _the_importance\n",
      "0.191742866729 _sitter\n",
      "0.19149006818 _in_this_paper\n",
      "0.189249661685 _with_the_help\n",
      "0.178361665592 _density_functional_theory\n",
      "0.176225984849 _moreover\n",
      "0.172192031276 _findings\n",
      "0.170371147013 _digital_sky_survey\n",
      "0.16914077622 _light_on_the\n",
      "0.16817646875 _an_application\n",
      "0.167948597591 _can_be_understood\n",
      "0.167927073467 _of_this_paper\n",
      "0.167459639578 _implications\n",
      "0.16322993558 _in_terms\n",
      "0.160868201056 _the_proof\n",
      "0.154876995257 _consequence\n",
      "0.1521142051 _examples\n",
      "0.151187683567 _also\n",
      "0.15070012151 _able_to\n",
      "0.145867114619 _further\n",
      "0.144117788257 _therefore\n",
      "0.143291436549 _in_addition_we\n",
      "0.142053416619 _illustrate\n",
      "0.140541086103 _suggests\n",
      "0.13845166315 _thus\n",
      "0.137725433325 _the_proposed\n",
      "0.136540227195 _are_shown\n",
      "0.13507066905 _paper_we_present\n",
      "0.134886339499 _briefly\n",
      "0.134399751698 _example\n",
      "0.133022602985 _first_time\n",
      "0.130779178091 _these_results\n",
      "0.130318407691 _gives_rise_to\n",
      "0.128749123094 _we_have_also\n",
      "0.127520614497 _hence\n",
      "0.127020208993 _context_of\n",
      "0.126636421773 _discussed\n",
      "0.125405079071 _importance_of\n"
     ]
    }
   ],
   "source": [
    "for i in eidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
