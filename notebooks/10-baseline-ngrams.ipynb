{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- bigrams / trigrams\n",
    "- pos tags\n",
    "- word count\n",
    "- avg word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import attr\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import islice\n",
    "from boltons.iterutils import windowed\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, path, skim=None):\n",
    "        self.path = path\n",
    "        self.skim = skim\n",
    "        \n",
    "    def lines(self):\n",
    "        with open(self.path) as fh:\n",
    "            for line in fh:\n",
    "                yield line.strip()\n",
    "    \n",
    "    def abstract_lines(self):\n",
    "        lines = []\n",
    "        for line in self.lines():\n",
    "            if line:\n",
    "                lines.append(line)\n",
    "            else:\n",
    "                yield lines\n",
    "                lines = []\n",
    "\n",
    "    def abstracts(self):\n",
    "        ab_lines = self.abstract_lines()\n",
    "        if self.skim:\n",
    "            ab_lines = islice(ab_lines, self.skim)\n",
    "        for lines in ab_lines:\n",
    "            yield Abstract.from_lines(lines)\n",
    "            \n",
    "    def xy(self, vocab):\n",
    "        for abstract in self.abstracts():\n",
    "            yield from abstract.xy(vocab)\n",
    "            \n",
    "    def ngram_counts(self, n):\n",
    "        counts = defaultdict(lambda: 0)\n",
    "        for ab in self.abstracts():\n",
    "            for sent in ab.sentences:\n",
    "                for ngram in sent.ngrams(n):\n",
    "                    counts[ngram] += 1\n",
    "        return Counter(counts)\n",
    "            \n",
    "    def most_common_ngrams(self, n, depth):\n",
    "        counts = self.ngram_counts(n)\n",
    "        return set([k for k, _ in counts.most_common(depth)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class Abstract:\n",
    "    \n",
    "    identifier = attr.ib()\n",
    "    tags = attr.ib()\n",
    "    sentences = attr.ib()\n",
    "    \n",
    "    @classmethod\n",
    "    def from_lines(cls, lines):\n",
    "        sentences = list(map(Sentence, lines[2:]))\n",
    "        return cls(lines[0], lines[1].split(), sentences)\n",
    "    \n",
    "    def sentence_tokens(self):\n",
    "        for sent in self.sentences:\n",
    "            yield re.findall('[a-z]+', sent.lower())\n",
    "    \n",
    "    def xy(self, vocab):\n",
    "        for i, sent in enumerate(self.sentences):\n",
    "            x = sent.features(vocab)\n",
    "            y = i / (len(self.sentences)-1)\n",
    "            yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence(str):\n",
    "    \n",
    "    def ngrams(self, n=1):\n",
    "        for ng in windowed(re.findall('[a-z]+', self.lower()), n):\n",
    "            yield '_'.join(ng)\n",
    "            \n",
    "    def ngram_counts(self, vocab, maxn=3):\n",
    "        for n in range(1, maxn+1):\n",
    "            counts = Counter(self.ngrams(n))\n",
    "            for k, v in counts.items():\n",
    "                if k in vocab:\n",
    "                    yield k, v\n",
    "                \n",
    "    def _features(self, vocab):\n",
    "        yield from self.ngram_counts(vocab)\n",
    "        \n",
    "    def features(self, vocab):\n",
    "        return dict(self._features(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = Corpus('../data/abstracts/train.txt', 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = (\n",
    "    train.most_common_ngrams(1, 2000) |\n",
    "    train.most_common_ngrams(2, 2000) |\n",
    "    train.most_common_ngrams(3, 2000)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = zip(*train.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = dv.fit_transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<537608x6000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 13879702 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = model.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Corpus('../data/abstracts/test.txt', 50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x, test_y = zip(*test.xy(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = dv.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31164644653867835"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(test_y, fit.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = dv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bidx = fit.coef_.argsort()\n",
    "eidx = np.flip(fit.coef_.argsort(), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.378732606239 particular_we\n",
      "-0.318681743544 other_hand\n",
      "-0.276923208589 of_the_art\n",
      "-0.225336885815 this_note\n",
      "-0.223746192725 the_context_of\n",
      "-0.21295682045 in_addition_to\n",
      "-0.208830371631 we_study\n",
      "-0.206363332024 the_help_of\n",
      "-0.197868956181 with_respect_to\n",
      "-0.19515577133 this_paper\n",
      "-0.1945329612 let\n",
      "-0.183986751552 de_sitter\n",
      "-0.178615046657 is_considered\n",
      "-0.178231787319 functional_theory\n",
      "-0.17324156592 an_application_we\n",
      "-0.163054934971 the_importance_of\n",
      "-0.160459851645 in_terms_of\n",
      "-0.158772493683 this_article\n",
      "-0.157906053727 is_presented\n",
      "-0.156809169835 we_investigate\n",
      "-0.156689843623 is_one_of\n",
      "-0.155257792639 is_studied\n",
      "-0.155004558615 we_report\n",
      "-0.151518151056 often\n",
      "-0.1478558958 usually\n",
      "-0.142693107995 the_first_part\n",
      "-0.141433957471 in_a_recent\n",
      "-0.140921001432 next_to\n",
      "-0.140265717868 phys\n",
      "-0.137217232219 is_devoted_to\n",
      "-0.135471331932 known_as\n",
      "-0.133587063545 we_present_results\n",
      "-0.133567407607 we_present\n",
      "-0.133113996164 has_been_studied\n",
      "-0.131176804579 and_therefore\n",
      "-0.129824568371 compare_our_results\n",
      "-0.129544916391 our_results_show\n",
      "-0.128415186124 but_also\n",
      "-0.126871458637 the_first_time\n",
      "-0.126688166462 gamma_ray_burst\n",
      "-0.126325056514 are_known_to\n",
      "-0.126003092191 the_proof_of\n",
      "-0.124394200129 large_number_of\n",
      "-0.122564408344 sloan_digital_sky\n",
      "-0.122435116851 we_consider\n",
      "-0.120110952689 the_notion_of\n",
      "-0.119327055662 been_shown_to\n",
      "-0.119295773417 known_that\n",
      "-0.117814494269 the_amount_of\n",
      "-0.117762055524 we_generalize_the\n"
     ]
    }
   ],
   "source": [
    "for i in bidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.460668856414 in_particular_we\n",
      "0.448326464864 the_other_hand\n",
      "0.375605860872 the_art\n",
      "0.320759381303 finally\n",
      "0.251145020152 application_we\n",
      "0.249359130003 as_a_corollary\n",
      "0.227539946345 here_we_report\n",
      "0.207757513213 conclude\n",
      "0.20053314286 in_this_paper\n",
      "0.200286770583 in_addition\n",
      "0.200069308624 with_respect\n",
      "0.196665660085 comment_on_the\n",
      "0.196442763941 the_importance\n",
      "0.189607266924 furthermore\n",
      "0.182297927864 with_the_help\n",
      "0.180462888464 monte_carlo\n",
      "0.180097999793 sitter\n",
      "0.177293204526 of_this_paper\n",
      "0.172533917045 an_application\n",
      "0.170214127339 can_be_understood\n",
      "0.167598592001 the_proof\n",
      "0.167023906793 light_on_the\n",
      "0.166510419429 in_terms\n",
      "0.165677632105 findings\n",
      "0.16458813856 implications\n",
      "0.163934881651 moreover\n",
      "0.16370468044 density_functional_theory\n",
      "0.157082418976 able_to\n",
      "0.151442958338 in_addition_we\n",
      "0.149677075407 consequence\n",
      "0.148872269619 digital_sky_survey\n",
      "0.14715021519 examples\n",
      "0.13925908221 illustrate\n",
      "0.138743381508 the_proposed\n",
      "0.138592746662 also\n",
      "0.138365638846 are_shown\n",
      "0.137464291596 first_time\n",
      "0.135961195704 paper_we_present\n",
      "0.135832645931 further\n",
      "0.134190824645 we_have_also\n",
      "0.133408609003 context_of\n",
      "0.133164536659 suggests\n",
      "0.133035619086 therefore\n",
      "0.131082463472 these_results\n",
      "0.130570662416 of_the_paper\n",
      "0.129856168781 in_this_article\n",
      "0.129167865519 large_number\n",
      "0.12868467922 importance_of\n",
      "0.127792940113 we_conclude\n",
      "0.126399495109 example\n"
     ]
    }
   ],
   "source": [
    "for i in eidx[:50]:\n",
    "    print(fit.coef_[i], names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
