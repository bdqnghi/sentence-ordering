{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from scipy.spatial import distance\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dclure/Projects/plot-ordering/env/lib/python3.6/site-packages/torch/serialization.py:367: SourceChangeWarning: source code of class 'sent_order.models.coref_embeds.DocEmbedder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "model = torch.load(\n",
    "    '../../data/coref-tag.bin',\n",
    "    map_location={'cuda:0': 'cpu'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocEmbedder(\n",
       "  (embeddings): WordEmbedding(39414, 300)\n",
       "  (lstm): LSTM(300, 500, batch_first=True, bidirectional=True)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 100, kernel_size=(2, 1000), stride=(1, 1))\n",
       "    (1): Conv2d(1, 100, kernel_size=(3, 1000), stride=(1, 1))\n",
       "    (2): Conv2d(1, 100, kernel_size=(4, 1000), stride=(1, 1))\n",
       "    (3): Conv2d(1, 100, kernel_size=(5, 1000), stride=(1, 1))\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5)\n",
       "  (embed): Sequential(\n",
       "    (0): Linear(in_features=1401, out_features=200, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('The report found that just 8 percent of Trump’s nominees for U.S. attorney positions are women, and just 8 percent are people of color. The report found a similar, if slightly less stark, trend when it comes to judgeships: 25 percent of Trump’s district court nominees and 19 percent of his circuit court nominees are women; 8 percent of Trump’s district court nominees and 11 percent of his circuit court nominees are people of color.')\n",
    "tokens = [str(t) for t in blob.tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'The'),\n",
       " (1, 'report'),\n",
       " (2, 'found'),\n",
       " (3, 'that'),\n",
       " (4, 'just'),\n",
       " (5, '8'),\n",
       " (6, 'percent'),\n",
       " (7, 'of'),\n",
       " (8, 'Trump'),\n",
       " (9, '’'),\n",
       " (10, 's'),\n",
       " (11, 'nominees'),\n",
       " (12, 'for'),\n",
       " (13, 'U.S.'),\n",
       " (14, 'attorney'),\n",
       " (15, 'positions'),\n",
       " (16, 'are'),\n",
       " (17, 'women'),\n",
       " (18, ','),\n",
       " (19, 'and'),\n",
       " (20, 'just'),\n",
       " (21, '8'),\n",
       " (22, 'percent'),\n",
       " (23, 'are'),\n",
       " (24, 'people'),\n",
       " (25, 'of'),\n",
       " (26, 'color'),\n",
       " (27, '.'),\n",
       " (28, 'The'),\n",
       " (29, 'report'),\n",
       " (30, 'found'),\n",
       " (31, 'a'),\n",
       " (32, 'similar'),\n",
       " (33, ','),\n",
       " (34, 'if'),\n",
       " (35, 'slightly'),\n",
       " (36, 'less'),\n",
       " (37, 'stark'),\n",
       " (38, ','),\n",
       " (39, 'trend'),\n",
       " (40, 'when'),\n",
       " (41, 'it'),\n",
       " (42, 'comes'),\n",
       " (43, 'to'),\n",
       " (44, 'judgeships'),\n",
       " (45, ':'),\n",
       " (46, '25'),\n",
       " (47, 'percent'),\n",
       " (48, 'of'),\n",
       " (49, 'Trump'),\n",
       " (50, '’'),\n",
       " (51, 's'),\n",
       " (52, 'district'),\n",
       " (53, 'court'),\n",
       " (54, 'nominees'),\n",
       " (55, 'and'),\n",
       " (56, '19'),\n",
       " (57, 'percent'),\n",
       " (58, 'of'),\n",
       " (59, 'his'),\n",
       " (60, 'circuit'),\n",
       " (61, 'court'),\n",
       " (62, 'nominees'),\n",
       " (63, 'are'),\n",
       " (64, 'women'),\n",
       " (65, ';'),\n",
       " (66, '8'),\n",
       " (67, 'percent'),\n",
       " (68, 'of'),\n",
       " (69, 'Trump'),\n",
       " (70, '’'),\n",
       " (71, 's'),\n",
       " (72, 'district'),\n",
       " (73, 'court'),\n",
       " (74, 'nominees'),\n",
       " (75, 'and'),\n",
       " (76, '11'),\n",
       " (77, 'percent'),\n",
       " (78, 'of'),\n",
       " (79, 'his'),\n",
       " (80, 'circuit'),\n",
       " (81, 'court'),\n",
       " (82, 'nominees'),\n",
       " (83, 'are'),\n",
       " (84, 'people'),\n",
       " (85, 'of'),\n",
       " (86, 'color'),\n",
       " (87, '.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "        [ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model([tokens])[0].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensor(1)\n",
      "report tensor(0)\n",
      "found tensor(0)\n",
      "that tensor(0)\n",
      "just tensor(0)\n",
      "8 tensor(0)\n",
      "percent tensor(0)\n",
      "of tensor(0)\n",
      "Trump tensor(0)\n",
      "’ tensor(0)\n",
      "s tensor(0)\n",
      "nominees tensor(0)\n",
      "for tensor(0)\n",
      "U.S. tensor(0)\n",
      "attorney tensor(0)\n",
      "positions tensor(0)\n",
      "are tensor(0)\n",
      "women tensor(0)\n",
      ", tensor(0)\n",
      "and tensor(0)\n",
      "just tensor(0)\n",
      "8 tensor(0)\n",
      "percent tensor(0)\n",
      "are tensor(0)\n",
      "people tensor(0)\n",
      "of tensor(0)\n",
      "color tensor(0)\n",
      ". tensor(0)\n",
      "The tensor(0)\n",
      "report tensor(0)\n",
      "found tensor(0)\n",
      "a tensor(0)\n",
      "similar tensor(0)\n",
      ", tensor(0)\n",
      "if tensor(0)\n",
      "slightly tensor(0)\n",
      "less tensor(0)\n",
      "stark tensor(0)\n",
      ", tensor(0)\n",
      "trend tensor(0)\n",
      "when tensor(0)\n",
      "it tensor(0)\n",
      "comes tensor(0)\n",
      "to tensor(0)\n",
      "judgeships tensor(0)\n",
      ": tensor(0)\n",
      "25 tensor(0)\n",
      "percent tensor(0)\n",
      "of tensor(0)\n",
      "Trump tensor(0)\n",
      "’ tensor(0)\n",
      "s tensor(0)\n",
      "district tensor(0)\n",
      "court tensor(0)\n",
      "nominees tensor(0)\n",
      "and tensor(0)\n",
      "19 tensor(0)\n",
      "percent tensor(0)\n",
      "of tensor(0)\n",
      "his tensor(1)\n",
      "circuit tensor(0)\n",
      "court tensor(0)\n",
      "nominees tensor(0)\n",
      "are tensor(0)\n",
      "women tensor(0)\n",
      "; tensor(0)\n",
      "8 tensor(0)\n",
      "percent tensor(0)\n",
      "of tensor(0)\n",
      "Trump tensor(0)\n",
      "’ tensor(0)\n",
      "s tensor(0)\n",
      "district tensor(0)\n",
      "court tensor(0)\n",
      "nominees tensor(0)\n",
      "and tensor(0)\n",
      "11 tensor(0)\n",
      "percent tensor(0)\n",
      "of tensor(0)\n",
      "his tensor(1)\n",
      "circuit tensor(0)\n",
      "court tensor(0)\n",
      "nominees tensor(0)\n",
      "are tensor(0)\n",
      "people tensor(0)\n",
      "of tensor(0)\n",
      "color tensor(0)\n",
      ". tensor(0)\n"
     ]
    }
   ],
   "source": [
    "for token, pred in zip(tokens, model([tokens])[0]):\n",
    "    print(token, pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = [e.detach().numpy() for e in model([tokens])[0]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
